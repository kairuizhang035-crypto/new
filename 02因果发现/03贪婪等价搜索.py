#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
03 è´ªå©ªç­‰ä»·æœç´¢ (Greedy Equivalence Search - GES)
éäº¤äº’å¼ç‰ˆæœ¬ï¼Œä½¿ç”¨AIC-Dè¯„åˆ†æ ‡å‡†

ä½œè€…: å› æœå‘ç°ç³»ç»Ÿ
æ—¥æœŸ: 2025å¹´

ç¯å¢ƒä¾èµ–:
- å¯é€‰GPUåŠ é€Ÿ: éœ€è¦å®‰è£…`torch>=2.1`ï¼ŒNVIDIAé©±åŠ¨ä¸CUDA(å»ºè®®11.8æˆ–12.x)
- æ— GPUæˆ–æ˜¾å­˜ä¸è¶³æ—¶å°†è‡ªåŠ¨å›é€€åˆ°CPUå¹¶ç»§ç»­è¿è¡Œ
- å¯é€šè¿‡ç¯å¢ƒå˜é‡`GES_FORCE_CPU=1`å¼ºåˆ¶ä½¿ç”¨CPU
"""

import pandas as pd
import numpy as np
from pgmpy.estimators import GES, StructureScore
import matplotlib.pyplot as plt
import networkx as nx
import os
import time
import json
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = ['sans-serif']
matplotlib.rcParams['font.sans-serif'] = [
    'SimHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
    'Noto Sans CJK SC', 'Source Han Sans SC', 'Microsoft YaHei',
    'DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans'
]
matplotlib.rcParams['axes.unicode_minus'] = False

def _detect_compute_mode():
    try:
        import torch
        import os as _os
        if _os.environ.get("GES_FORCE_CPU", "0") == "1":
            return "cpu"
        if torch.cuda.is_available():
            return "gpu"
    except Exception:
        pass
    return "cpu"

def load_data():
    """åŠ è½½æ•°æ®"""
    input_file = "/home/zkr/å› æœå‘ç°3/01æ•°æ®é¢„å¤„ç†/ç¼©å‡æ•°æ®_è§„æ ¼.csv"
    
    # å°è¯•ä½¿ç”¨utf-8ç¼–ç 
    try:
        df = pd.read_csv(input_file, encoding='utf-8', header=0, index_col=0)
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(input_file, encoding='utf-8-sig', header=0, index_col=0)
        except UnicodeDecodeError:
            df = pd.read_csv(input_file, encoding='latin-1', header=0, index_col=0)
    
    df = df.dropna(axis=1, how='all')
    df = df.astype('float32')
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    return df

class AICDScoreGPU(StructureScore):
    def __init__(self, data, mode="cpu", **kwargs):
        super(AICDScoreGPU, self).__init__(data=data, **kwargs)
        self.mode = mode
        self.cols = list(self.data.columns)
        self.codes = []
        self.card = []
        for c in self.cols:
            cat = pd.Categorical(self.data[c])
            code = cat.codes.astype(np.int64)
            self.codes.append(code)
            self.card.append(int((code.max() + 1) if code.size else 0))
        self.codes = np.vstack(self.codes).T if len(self.codes) > 0 else np.empty((0, 0), dtype=np.int64)
        self.card = np.array(self.card, dtype=np.int64)
        self.cache = {}
        self.device = None
        self.use_gpu = False
        if self.mode == "gpu":
            try:
                import torch
                if torch.cuda.is_available() and self.codes.size > 0:
                    self.device = torch.device("cuda")
                    try:
                        self.tcodes = torch.tensor(self.codes, dtype=torch.int64, device=self.device)
                        self.tcard = torch.tensor(self.card, dtype=torch.int64, device=self.device)
                        self.use_gpu = True
                    except RuntimeError as e:
                        if "out of memory" in str(e).lower() or "cuda" in str(e).lower():
                            try:
                                torch.cuda.empty_cache()
                            except Exception:
                                pass
                            self.use_gpu = False
                else:
                    self.use_gpu = False
            except Exception:
                self.use_gpu = False

    def _local_score_cpu(self, vi, pidx):
        r = int(self.card[vi])
        if r == 0:
            return 0.0
        if len(pidx) == 0:
            x = self.codes[:, vi]
            counts = np.bincount(x, minlength=r).astype(np.float64)
            total = counts.sum()
            if total == 0:
                return 0.0
            mask = counts > 0
            ll = float((counts[mask] * (np.log(counts[mask]) - np.log(total))).sum())
            num_parents_states = 1
            return ll - num_parents_states * (r - 1)
        strides = []
        q = 1
        for idx in pidx:
            strides.append(q)
            q *= int(self.card[idx])
        if q == 0:
            return 0.0
        gp = np.zeros(self.codes.shape[0], dtype=np.int64)
        for s, idx in zip(strides, pidx):
            gp = gp + self.codes[:, idx] * int(s)
        combined = gp * r + self.codes[:, vi]
        counts = np.bincount(combined, minlength=q * r).astype(np.float64)
        mat = counts.reshape(q, r)
        n_pa = mat.sum(axis=1)
        rows = n_pa > 0
        if np.any(rows):
            mat2 = mat[rows]
            npa2 = n_pa[rows][:, None]
            ll = float((mat2 * (np.log(np.clip(mat2, 1, None)) - np.log(npa2))).sum())
        else:
            ll = 0.0
        num_parents_states = q
        return ll - num_parents_states * (r - 1)

    def _local_score_gpu(self, vi, pidx):
        import torch
        r = int(self.card[vi])
        if r == 0:
            return 0.0
        try:
            if len(pidx) == 0:
                tx = self.tcodes[:, vi]
                counts = torch.bincount(tx, minlength=r).double()
                total = counts.sum()
                if float(total.item()) == 0.0:
                    return 0.0
                mask = counts > 0
                ll = float((counts[mask] * (torch.log(counts[mask]) - torch.log(total))).sum().item())
                num_parents_states = 1
                return ll - num_parents_states * (r - 1)
            strides = []
            q = 1
            for idx in pidx:
                strides.append(q)
                q *= int(self.card[idx])
            if q == 0:
                return 0.0
            gp = torch.zeros(self.tcodes.shape[0], dtype=torch.int64, device=self.device)
            for s, idx in zip(strides, pidx):
                gp = gp + self.tcodes[:, idx] * int(s)
            combined = gp * r + self.tcodes[:, vi]
            counts = torch.bincount(combined, minlength=q * r).double()
            mat = counts.view(q, r)
            n_pa = mat.sum(dim=1)
            rows_mask = n_pa > 0
            if torch.any(rows_mask):
                mat2 = mat[rows_mask]
                npa2 = n_pa[rows_mask].unsqueeze(1)
                ll = float((mat2 * (torch.log(mat2.clamp_min(1)) - torch.log(npa2))).sum().item())
            else:
                ll = 0.0
            num_parents_states = q
            return ll - num_parents_states * (r - 1)
        except RuntimeError as e:
            if "CUDA" in str(e):
                self.use_gpu = False
                return self._local_score_cpu(vi, pidx)
            raise

    def local_score(self, variable, parents):
        vi = self.cols.index(variable) if isinstance(variable, str) else int(variable)
        pidx = [(self.cols.index(p) if isinstance(p, str) else int(p)) for p in (parents or [])]
        key = (vi, tuple(sorted(pidx)))
        cached = self.cache.get(key)
        if cached is not None:
            return cached
        if self.use_gpu:
            val = self._local_score_gpu(vi, pidx)
        else:
            val = self._local_score_cpu(vi, pidx)
        self.cache[key] = val
        return val

    def structure_prior(self, model):
        return 0

    def structure_prior_ratio(self, operation):
        return 0

def create_output_folder():
    """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(script_dir, "03è´ªå©ªç­‰ä»·æœç´¢ç»“æœ")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def save_dag_results(dag, output_folder, df_columns):
    """ä¿å­˜DAGç»“æœåˆ°æ–‡ä»¶"""
    edges = list(dag.edges())
    
    # ä¿å­˜TXTæ ¼å¼
    txt_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœè¾¹å®Œæ•´.txt")
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("è´ªå©ªç­‰ä»·æœç´¢ (GES-AIC-D) å‘ç°çš„å› æœè¾¹\n")
        f.write("=" * 40 + "\n")
        for i, edge in enumerate(edges, 1):
            f.write(f"{i:3d}. {edge[0]} -> {edge[1]}\n")
    
    # ä¿å­˜CSVæ ¼å¼
    df_edges = pd.DataFrame(edges, columns=["æºèŠ‚ç‚¹", "ç›®æ ‡èŠ‚ç‚¹"])
    csv_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœè¾¹åˆ—è¡¨.csv")
    df_edges.to_csv(csv_file, index=False, encoding="utf-8-sig")
    
    # ç”Ÿæˆç½‘ç»œå›¾
    plt.figure(figsize=(16, 12))
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
    
    # ç»˜åˆ¶èŠ‚ç‚¹
    nx.draw_networkx_nodes(G, pos, 
                          node_color='lightgreen', 
                          node_size=2000,
                          alpha=0.8)
    
    # ç»˜åˆ¶è¾¹
    nx.draw_networkx_edges(G, pos, 
                          edge_color='gray',
                          arrows=True,
                          arrowsize=20,
                          arrowstyle='->',
                          width=1.5,
                          alpha=0.7)
    
    # ç»˜åˆ¶æ ‡ç­¾
    nx.draw_networkx_labels(G, pos, 
                           font_size=10,
                           font_weight='bold',
                           font_family='sans-serif')
    
    plt.title(f"è´ªå©ªç­‰ä»·æœç´¢ (GES-AIC-D) å› æœç½‘ç»œå›¾\nå…±{len(edges)}æ¡å› æœè¾¹", fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    
    graph_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœç½‘ç»œå›¾.png")
    plt.savefig(graph_file, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    
    # åˆ›å»ºè¯¦ç»†JSONç»“æœ
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    in_degrees = dict(G.in_degree())
    out_degrees = dict(G.out_degree())
    
    results = {
        "ç®—æ³•ä¿¡æ¯": {
            "ç®—æ³•åç§°": "è´ªå©ªç­‰ä»·æœç´¢ (Greedy Equivalence Search - GES)",
            "è¯„åˆ†æ–¹æ³•": "AIC-D (Akaike Information Criterion - Discrete)",
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ•°æ®ç»´åº¦": {
                "æ ·æœ¬æ•°": len(df_columns),
                "å˜é‡æ•°": len(df_columns)
            }
        },
        "ç½‘ç»œç»“æ„": {
            "èŠ‚ç‚¹æ€»æ•°": len(dag.nodes()),
            "è¾¹æ€»æ•°": len(edges),
            "èŠ‚ç‚¹åˆ—è¡¨": list(dag.nodes()),
            "å› æœè¾¹åˆ—è¡¨": [{"æºèŠ‚ç‚¹": edge[0], "ç›®æ ‡èŠ‚ç‚¹": edge[1]} for edge in edges]
        },
        "ç»Ÿè®¡ä¿¡æ¯": {
            "å…¥åº¦ç»Ÿè®¡": {node: in_degrees.get(node, 0) for node in dag.nodes()},
            "å‡ºåº¦ç»Ÿè®¡": {node: out_degrees.get(node, 0) for node in dag.nodes()},
            "æœ€å¤§å…¥åº¦": max(in_degrees.values()) if in_degrees else 0,
            "æœ€å¤§å‡ºåº¦": max(out_degrees.values()) if out_degrees else 0,
            "å¹³å‡åº¦æ•°": sum(dict(G.degree()).values()) / len(dag.nodes()) if dag.nodes() else 0
        },
        "èŠ‚ç‚¹åˆ†æ": {
            "æ ¹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) == 0],
            "å¶èŠ‚ç‚¹": [node for node in dag.nodes() if out_degrees.get(node, 0) == 0],
            "ä¸­ä»‹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) > 0 and out_degrees.get(node, 0) > 0]
        }
    }
    
    json_file = os.path.join(output_folder, "GreedyEquivalence_AIC-D_å› æœç»“æœ.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return txt_file, csv_file, graph_file, json_file, results

def run_ges_algorithm():
    """è¿è¡Œè´ªå©ªç­‰ä»·æœç´¢ç®—æ³•"""
    print("=" * 60)
    print("03 è´ªå©ªç­‰ä»·æœç´¢ (GES) - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    df = load_data()
    
    # 2. åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = create_output_folder()
    
    # 3. ä½¿ç”¨AIC-Dè¯„åˆ†æ–¹æ³•è¿è¡ŒGESç®—æ³•
    mode = _detect_compute_mode()
    print(f"è®¡ç®—æ¨¡å¼: {mode}")
    print("æ­£åœ¨è¿è¡Œè´ªå©ªç­‰ä»·æœç´¢ (GES-AIC-Dè¯„åˆ†)...")
    if mode == "gpu":
        print("GPUåŠ é€Ÿå¯ç”¨: éœ€è¦å®‰è£…`torch`å¹¶ä¸”å¯ç”¨CUDAé©±åŠ¨ (å»ºè®®CUDA 11.8/12.x)ã€‚æ˜¾å­˜ä¸è¶³å°†è‡ªåŠ¨å›é€€CPUã€‚")
    start_time = time.time()
    
    try:
        ges = GES(df)
        if mode == "gpu":
            score = AICDScoreGPU(df, mode="gpu")
            dag = ges.estimate(scoring_method=score)
        else:
            dag = ges.estimate(scoring_method='aic-d')
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"âœ“ è´ªå©ªç­‰ä»·æœç´¢å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
        print(f"âœ“ å‘ç° {len(dag.edges())} æ¡å› æœè¾¹")
        
        # 4. ä¿å­˜ç»“æœ
        txt_file, csv_file, graph_file, json_file, results = save_dag_results(dag, output_dir, df.columns)
        
        # 5. è¾“å‡ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡Œå®Œæˆ - ç»“æœæ‘˜è¦")
        print("=" * 60)
        print(f"è¯„åˆ†æ–¹æ³•: AIC-D")
        print(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"æ•°æ®ç»´åº¦: {df.shape[0]} Ã— {df.shape[1]}")
        print(f"å‘ç°çš„å› æœè¾¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['è¾¹æ€»æ•°']}")
        print(f"ç½‘ç»œèŠ‚ç‚¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['èŠ‚ç‚¹æ€»æ•°']}")
        print(f"æ ¹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['æ ¹èŠ‚ç‚¹'])}")
        print(f"å¶èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['å¶èŠ‚ç‚¹'])}")
        print(f"ä¸­ä»‹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['ä¸­ä»‹èŠ‚ç‚¹'])}")
        print(f"å¹³å‡èŠ‚ç‚¹åº¦æ•°: {results['ç»Ÿè®¡ä¿¡æ¯']['å¹³å‡åº¦æ•°']:.2f}")
        
        print(f"\nğŸ“ ç»“æœä¿å­˜ä½ç½®:")
        print(f"  - TXTæ–‡ä»¶: {txt_file}")
        print(f"  - CSVæ–‡ä»¶: {csv_file}")
        print(f"  - ç½‘ç»œå›¾: {graph_file}")
        print(f"  - JSONç»“æœ: {json_file}")
        
        return output_dir, len(dag.edges())
        
    except Exception as e:
        print(f"âŒ è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        output_dir, edge_count = run_ges_algorithm()
        print(f"\nâœ… 03 è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡ŒæˆåŠŸï¼å‘ç° {edge_count} æ¡å› æœè¾¹")
    except Exception as e:
        print(f"\nâŒ 03 è´ªå©ªç­‰ä»·æœç´¢æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise
