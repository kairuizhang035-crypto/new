#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
02 çˆ¬å±±ç®—æ³• (Hill Climbing Search)
éäº¤äº’å¼ç‰ˆæœ¬ï¼Œä½¿ç”¨AIC-Dè¯„åˆ†æ ‡å‡†

ä½œè€…: å› æœå‘ç°ç³»ç»Ÿ
æ—¥æœŸ: 2025å¹´
"""

import pandas as pd
import numpy as np
from pgmpy.estimators import HillClimbSearch
from pgmpy.models import BayesianNetwork
from pgmpy.estimators import MaximumLikelihoodEstimator
import matplotlib.pyplot as plt
import networkx as nx
import os
import time
import json
from datetime import datetime

# è®¾ç½®ä¸­æ–‡å­—ä½“
import matplotlib
matplotlib.rcParams['font.family'] = ['sans-serif']
matplotlib.rcParams['font.sans-serif'] = [
    'SimHei', 'WenQuanYi Micro Hei', 'WenQuanYi Zen Hei', 
    'Noto Sans CJK SC', 'Source Han Sans SC', 'Microsoft YaHei',
    'DejaVu Sans', 'Arial Unicode MS', 'Liberation Sans'
]
matplotlib.rcParams['axes.unicode_minus'] = False

def _detect_compute_mode():
    try:
        import torch
        if torch.cuda.is_available():
            return "gpu"
    except Exception:
        pass
    return "cpu"

def load_data():
    """åŠ è½½æ•°æ®"""
    input_file = "/home/zkr/å› æœå‘ç°3/01æ•°æ®é¢„å¤„ç†/ç¼©å‡æ•°æ®_è§„æ ¼.csv"
    
    # å°è¯•ä½¿ç”¨utf-8ç¼–ç 
    try:
        df = pd.read_csv(input_file, encoding='utf-8', header=0, index_col=0)
    except UnicodeDecodeError:
        try:
            df = pd.read_csv(input_file, encoding='utf-8-sig', header=0, index_col=0)
        except UnicodeDecodeError:
            df = pd.read_csv(input_file, encoding='latin-1', header=0, index_col=0)
    
    df = df.dropna(axis=1, how='all')
    df = df.astype('float32')
    
    print(f"âœ“ æ•°æ®åŠ è½½å®Œæˆ: {df.shape}")
    return df

class AICDScoreCached:
    def __init__(self, df, mode="cpu"):
        self.mode = mode
        self.df = df.copy()
        self.cols = list(self.df.columns)
        self.n = len(self.cols)
        self.codes = []
        self.card = []
        for c in self.cols:
            cat = pd.Categorical(self.df[c])
            code = cat.codes.astype(np.int64)
            self.codes.append(code)
            self.card.append(int(code.max() + 1))
        self.codes = np.vstack(self.codes).T
        self.card = np.array(self.card, dtype=np.int64)
        self.cache = {}
        self.device = None
        self.use_gpu = False
        if self.mode == "gpu":
            try:
                import torch
                if torch.cuda.is_available():
                    self.device = torch.device("cuda")
                    self.tcodes = torch.tensor(self.codes, dtype=torch.int64, device=self.device)
                    self.tcard = torch.tensor(self.card, dtype=torch.int64, device=self.device)
                    self.use_gpu = True
            except Exception:
                self.use_gpu = False

    def local_score(self, var, parents):
        if isinstance(var, str):
            vi = self.cols.index(var)
        else:
            vi = int(var)
        pidx = []
        for p in parents or []:
            pidx.append(self.cols.index(p) if isinstance(p, str) else int(p))
        key = (vi, tuple(sorted(pidx)))
        if key in self.cache:
            return self.cache[key]
        r = int(self.card[vi])
        if len(pidx) == 0:
            x = self.codes[:, vi]
            if self.use_gpu:
                import torch
                tx = self.tcodes[:, vi]
                counts = torch.bincount(tx, minlength=r).double()
                total = counts.sum()
                probs = (counts + 1e-12) / (total + 1e-12)
                ll = float((counts * torch.log(probs)).sum().item())
            else:
                counts = np.bincount(x, minlength=r).astype(np.float64)
                total = counts.sum()
                probs = (counts + 1e-12) / (total + 1e-12)
                ll = float((counts * np.log(probs)).sum())
            num_parents_states = 1
            score = ll - num_parents_states * (r - 1)
            self.cache[key] = score
            return score
        strides = []
        q = 1
        for idx in pidx:
            strides.append(q)
            q *= int(self.card[idx])
        if self.use_gpu:
            import torch
            gp = torch.zeros(self.tcodes.shape[0], dtype=torch.int64, device=self.device)
            for s, idx in zip(strides, pidx):
                gp = gp + self.tcodes[:, idx] * int(s)
            combined = gp * r + self.tcodes[:, vi]
            counts = torch.bincount(combined, minlength=q * r).double()
            mat = counts.view(q, r)
            n_pa = mat.sum(dim=1)
            probs = (mat + 1e-12) / (n_pa.unsqueeze(1) + 1e-12)
            ll = float((mat * torch.log(probs)).sum().item())
        else:
            gp = np.zeros(self.codes.shape[0], dtype=np.int64)
            for s, idx in zip(strides, pidx):
                gp = gp + self.codes[:, idx] * int(s)
            combined = gp * r + self.codes[:, vi]
            counts = np.bincount(combined, minlength=q * r).astype(np.float64)
            mat = counts.reshape(q, r)
            n_pa = mat.sum(axis=1)
            probs = (mat + 1e-12) / (n_pa[:, None] + 1e-12)
            ll = float((mat * np.log(probs)).sum())
        num_parents_states = q
        score = ll - num_parents_states * (r - 1)
        self.cache[key] = score
        return score

def hill_climb_gpu(df, max_indegree=None, epsilon=1e-4, mode="cpu"):
    cols = list(df.columns)
    G = nx.DiGraph()
    G.add_nodes_from(cols)
    score = AICDScoreCached(df, mode=mode)
    parents = {c: [] for c in cols}
    local = {c: score.local_score(c, []) for c in cols}
    while True:
        best = None
        best_delta = None
        best_op = None
        for u in cols:
            for v in cols:
                if u == v:
                    continue
                if G.has_edge(u, v):
                    continue
                if max_indegree is not None and len(parents[v]) >= max_indegree:
                    continue
                if nx.has_path(G, v, u):
                    continue
                new_parents = parents[v] + [u]
                new_score = score.local_score(v, new_parents)
                delta = new_score - local[v]
                if (best_delta is None) or (delta > best_delta):
                    best_delta = delta
                    best = (u, v)
                    best_op = "add"
        for u, v in list(G.edges()):
            new_parents = [p for p in parents[v] if p != u]
            new_score = score.local_score(v, new_parents)
            delta = new_score - local[v]
            if (best_delta is None) or (delta > best_delta):
                best_delta = delta
                best = (u, v)
                best_op = "remove"
        for u, v in list(G.edges()):
            if max_indegree is not None and len(parents[u]) >= max_indegree:
                continue
            if nx.has_path(G, u, v):
                continue
            if nx.has_path(G, v, u):
                continue
            new_parents_v = [p for p in parents[v] if p != u]
            new_parents_u = parents[u] + [v]
            s_v = score.local_score(v, new_parents_v)
            s_u = score.local_score(u, new_parents_u)
            delta = (s_v - local[v]) + (s_u - local[u])
            if (best_delta is None) or (delta > best_delta):
                best_delta = delta
                best = (u, v)
                best_op = "reverse"
        if best_op is None or (best_delta is None) or (best_delta < epsilon):
            break
        u, v = best
        if best_op == "add":
            G.add_edge(u, v)
            parents[v] = parents[v] + [u]
            local[v] = score.local_score(v, parents[v])
        elif best_op == "remove":
            G.remove_edge(u, v)
            parents[v] = [p for p in parents[v] if p != u]
            local[v] = score.local_score(v, parents[v])
        elif best_op == "reverse":
            G.remove_edge(u, v)
            parents[v] = [p for p in parents[v] if p != u]
            local[v] = score.local_score(v, parents[v])
            G.add_edge(v, u)
            parents[u] = parents[u] + [v]
            local[u] = score.local_score(u, parents[u])
    return G

def create_output_folder():
    """åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹"""
    script_dir = os.path.dirname(os.path.abspath(__file__))
    output_dir = os.path.join(script_dir, "02çˆ¬å±±ç®—æ³•ç»“æœ")
    os.makedirs(output_dir, exist_ok=True)
    return output_dir

def save_dag_results(dag, output_folder, df_columns):
    """ä¿å­˜DAGç»“æœåˆ°æ–‡ä»¶"""
    edges = list(dag.edges())
    
    # ä¿å­˜TXTæ ¼å¼
    txt_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœè¾¹å®Œæ•´.txt")
    with open(txt_file, 'w', encoding='utf-8') as f:
        f.write("çˆ¬å±±ç®—æ³• (AIC-D) å‘ç°çš„å› æœè¾¹\n")
        f.write("=" * 40 + "\n")
        for i, edge in enumerate(edges, 1):
            f.write(f"{i:3d}. {edge[0]} -> {edge[1]}\n")
    
    # ä¿å­˜CSVæ ¼å¼
    df_edges = pd.DataFrame(edges, columns=["æºèŠ‚ç‚¹", "ç›®æ ‡èŠ‚ç‚¹"])
    csv_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœè¾¹åˆ—è¡¨.csv")
    df_edges.to_csv(csv_file, index=False, encoding="utf-8-sig")
    
    # ç”Ÿæˆç½‘ç»œå›¾
    plt.figure(figsize=(16, 12))
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    pos = nx.spring_layout(G, k=3, iterations=50, seed=42)
    
    # ç»˜åˆ¶èŠ‚ç‚¹
    nx.draw_networkx_nodes(G, pos, 
                          node_color='lightcoral', 
                          node_size=2000,
                          alpha=0.8)
    
    # ç»˜åˆ¶è¾¹
    nx.draw_networkx_edges(G, pos, 
                          edge_color='gray',
                          arrows=True,
                          arrowsize=20,
                          arrowstyle='->',
                          width=1.5,
                          alpha=0.7)
    
    # ç»˜åˆ¶æ ‡ç­¾
    nx.draw_networkx_labels(G, pos, 
                           font_size=10,
                           font_weight='bold',
                           font_family='sans-serif')
    
    plt.title(f"çˆ¬å±±ç®—æ³• (AIC-D) å› æœç½‘ç»œå›¾\nå…±{len(edges)}æ¡å› æœè¾¹", fontsize=16, fontweight='bold')
    plt.axis('off')
    plt.tight_layout()
    
    graph_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœç½‘ç»œå›¾.png")
    plt.savefig(graph_file, dpi=300, bbox_inches='tight', 
                facecolor='white', edgecolor='none')
    plt.close()
    
    # åˆ›å»ºè¯¦ç»†JSONç»“æœ
    G = nx.DiGraph()
    G.add_edges_from(edges)
    
    in_degrees = dict(G.in_degree())
    out_degrees = dict(G.out_degree())
    
    results = {
        "ç®—æ³•ä¿¡æ¯": {
            "ç®—æ³•åç§°": "çˆ¬å±±ç®—æ³• (Hill Climbing Search)",
            "è¯„åˆ†æ–¹æ³•": "AIC-D (Akaike Information Criterion - Discrete)",
            "ç”Ÿæˆæ—¶é—´": datetime.now().strftime("%Y-%m-%d %H:%M:%S"),
            "æ•°æ®ç»´åº¦": {
                "æ ·æœ¬æ•°": len(df_columns),
                "å˜é‡æ•°": len(df_columns)
            }
        },
        "ç½‘ç»œç»“æ„": {
            "èŠ‚ç‚¹æ€»æ•°": len(dag.nodes()),
            "è¾¹æ€»æ•°": len(edges),
            "èŠ‚ç‚¹åˆ—è¡¨": list(dag.nodes()),
            "å› æœè¾¹åˆ—è¡¨": [{"æºèŠ‚ç‚¹": edge[0], "ç›®æ ‡èŠ‚ç‚¹": edge[1]} for edge in edges]
        },
        "ç»Ÿè®¡ä¿¡æ¯": {
            "å…¥åº¦ç»Ÿè®¡": {node: in_degrees.get(node, 0) for node in dag.nodes()},
            "å‡ºåº¦ç»Ÿè®¡": {node: out_degrees.get(node, 0) for node in dag.nodes()},
            "æœ€å¤§å…¥åº¦": max(in_degrees.values()) if in_degrees else 0,
            "æœ€å¤§å‡ºåº¦": max(out_degrees.values()) if out_degrees else 0,
            "å¹³å‡åº¦æ•°": sum(dict(G.degree()).values()) / len(dag.nodes()) if dag.nodes() else 0
        },
        "èŠ‚ç‚¹åˆ†æ": {
            "æ ¹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) == 0],
            "å¶èŠ‚ç‚¹": [node for node in dag.nodes() if out_degrees.get(node, 0) == 0],
            "ä¸­ä»‹èŠ‚ç‚¹": [node for node in dag.nodes() if in_degrees.get(node, 0) > 0 and out_degrees.get(node, 0) > 0]
        }
    }
    
    json_file = os.path.join(output_folder, "HillClimbing_AIC-D_å› æœç»“æœ.json")
    with open(json_file, 'w', encoding='utf-8') as f:
        json.dump(results, f, ensure_ascii=False, indent=2)
    
    return txt_file, csv_file, graph_file, json_file, results

def run_hillclimbing_algorithm():
    """è¿è¡Œçˆ¬å±±ç®—æ³•"""
    print("=" * 60)
    print("02 çˆ¬å±±ç®—æ³• (Hill Climbing Search) - å¼€å§‹æ‰§è¡Œ")
    print("=" * 60)
    
    # 1. åŠ è½½æ•°æ®
    df = load_data()
    
    # 2. åˆ›å»ºè¾“å‡ºæ–‡ä»¶å¤¹
    output_dir = create_output_folder()
    
    mode = _detect_compute_mode()
    print(f"è®¡ç®—æ¨¡å¼: {mode}")
    print("æ­£åœ¨è¿è¡Œçˆ¬å±±ç®—æ³• (AIC-Dè¯„åˆ†)...")
    start_time = time.time()
    
    try:
        if mode == "gpu":
            dag_graph = hill_climb_gpu(df, mode="gpu")
            dag = nx.DiGraph(dag_graph)
        else:
            hc = HillClimbSearch(df)
            dag = hc.estimate(scoring_method='aic-d')
        
        end_time = time.time()
        execution_time = end_time - start_time
        
        print(f"âœ“ çˆ¬å±±ç®—æ³•å®Œæˆï¼Œè€—æ—¶: {execution_time:.2f}ç§’")
        print(f"âœ“ å‘ç° {len(dag.edges())} æ¡å› æœè¾¹")
        
        # 4. ä¿å­˜ç»“æœ
        txt_file, csv_file, graph_file, json_file, results = save_dag_results(dag, output_dir, df.columns)
        
        # 5. è¾“å‡ºç»“æœæ‘˜è¦
        print("\n" + "=" * 60)
        print("çˆ¬å±±ç®—æ³•æ‰§è¡Œå®Œæˆ - ç»“æœæ‘˜è¦")
        print("=" * 60)
        print(f"è¯„åˆ†æ–¹æ³•: AIC-D")
        print(f"æ‰§è¡Œæ—¶é—´: {execution_time:.2f}ç§’")
        print(f"æ•°æ®ç»´åº¦: {df.shape[0]} Ã— {df.shape[1]}")
        print(f"å‘ç°çš„å› æœè¾¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['è¾¹æ€»æ•°']}")
        print(f"ç½‘ç»œèŠ‚ç‚¹æ•°é‡: {results['ç½‘ç»œç»“æ„']['èŠ‚ç‚¹æ€»æ•°']}")
        print(f"æ ¹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['æ ¹èŠ‚ç‚¹'])}")
        print(f"å¶èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['å¶èŠ‚ç‚¹'])}")
        print(f"ä¸­ä»‹èŠ‚ç‚¹æ•°é‡: {len(results['èŠ‚ç‚¹åˆ†æ']['ä¸­ä»‹èŠ‚ç‚¹'])}")
        print(f"å¹³å‡èŠ‚ç‚¹åº¦æ•°: {results['ç»Ÿè®¡ä¿¡æ¯']['å¹³å‡åº¦æ•°']:.2f}")
        
        print(f"\nğŸ“ ç»“æœä¿å­˜ä½ç½®:")
        print(f"  - TXTæ–‡ä»¶: {txt_file}")
        print(f"  - CSVæ–‡ä»¶: {csv_file}")
        print(f"  - ç½‘ç»œå›¾: {graph_file}")
        print(f"  - JSONç»“æœ: {json_file}")
        
        return output_dir, len(dag.edges())
        
    except Exception as e:
        print(f"âŒ çˆ¬å±±ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise

if __name__ == "__main__":
    try:
        output_dir, edge_count = run_hillclimbing_algorithm()
        print(f"\nâœ… 02 çˆ¬å±±ç®—æ³•æ‰§è¡ŒæˆåŠŸï¼å‘ç° {edge_count} æ¡å› æœè¾¹")
    except Exception as e:
        print(f"\nâŒ 02 çˆ¬å±±ç®—æ³•æ‰§è¡Œå¤±è´¥: {str(e)}")
        raise
